The proposal that is put forth is this paper is mainly motiviated by two works.
%
First, several of the theoretical and empirical studies developed by Montgomery et al.~\cite{montgomery2012simple} show the 
important issues related to premature convergence that appear in \DE{}.
%
Second, some works of Segura et al.~\cite{segura2016novel} propose a new replacement strategy (\MULTIDYN{}) to deal with premature 
convergence in memetic algorithms
for combinatorial optimization by biasing the decisions of the optimizer in base of the stopping criterion and elapsed generations.
%
Given the conclusions of these previous works, the proposal of this paper is a novel \DE{} variant that includes an explicit mechanism 
that takes into account the stopping criterion and elapsed generations to prevent premature convergence.
%
This novel optimizer is called Differential Evolution with Enhanced Diversity Maintenance (\DEEDM{}) and its source
code is freely available~\footnote{The code in C++ can be downloaded in the next link \url{https://github.com/joelchaconcastillo/Diversity\_DE\_Research.git}}.

\MULTIDYN{} is a replacement strategy that considers the maximization of the diversity 
contribution of each individual as an explicit objective.
%
Then, the notion of Pareto dominance is used to select the survivors.
%
It uses a dynamic threshold to prevent the selection of individuals with a too low contribution to diversity.
%
One of the main weaknesses of this method is that its convergence is highly delayed.
%
Thus, executions of several days were required to attain high-quality solutions.
%
As a result our proposal incorporates two extensions to alleviate such a drawback.

\DEEDM{} alters the replacement strategy of \DE{} with the aim of controlling the 
balance between exploration and exploitation.
%
The main principle of the novel replacement strategy is similar to the one used in \MULTIDYN{}, i.e.
individuals that contribute too little to diversity should not be accepted as target vectors of the next generation.
%
The contribution to diversity is estimated with the Distance to Closest Neighbour metric (\DCN{}), i.e. given
a set of already selected individuals ($Survivors$), the contribution of a non-selected one is calculated as the minimum
distance to any of the individuals in $Survivors$.
%
However, in order to promote a faster convergence than in \MULTIDYN{} two modifications are performed.
%
First, no concepts of the multi-objective field are applied, instead a more greedy selection is taken into account.
%
Second, a new population called the elite population is used.

Our replacement strategy (see Algorithm \ref{alg:Replacement}) operates as follows.
%
It receives as input the target population, the offspring population and the elite population of the current generation and
it must generate the next target population.
%
Additionally, it reaceives the desired minimum distance $D_d$.
%
First, it joins the three populations in a set of current members.
%
The current members set contains vectors that might be selected to survive.
%
Then, the set of survivors and penalized individuals are initialized to the empty set.
%
In order to select the $NP$ target vectors an iterative process is repeated.
%
In each step the best individual in the $Current$ set, i.e. the one with best objective function is selected
to survive, i.e. moved to the $Survivors$ set.
%
Then, individuals in the $Current$ set to the selected individual lower the $D_d$ are transferred to the
$Penalized$ set.
%
In the case that the $Current$ set is empty previous to the selection of $NP$ individuals, the target
population is filled by selecting in each step the individual with a largest \DCN{} to the survivors set.


\begin{algorithm}[H]
\algsetup{linenosize=\tiny}
  \scriptsize
	\caption{Replacement Phase} \label{alg:Replacement}
	\begin{algorithmic}[1]
	\STATE Input: $D_d$, $Population$, $Offspring$ and $Elite$
	\STATE $Current = Population \cup Offspring \cup Elite$.
	\STATE $Survivors = Penalized = \emptyset$.
	\WHILE{ $Survivors < NP$ }
	   \STATE Select the best individual $Current_{best}$ of $Current$ as a new seed.
	   \STATE Find the other individuals nearest according to Eq. (\ref{eqn:distance}) and move to $Penalized$.
	   \STATE Move the best individual $Current_{best}$ to $Survivors$.
	\ENDWHILE
	\WHILE{ $Survivors < pop\_size$ }
	   \STATE Select the individual $Penalized$ with maximum distance to closest $Survivor$.
	   \STATE Move individual $Penalized$ to $Survivors$.
	\ENDWHILE
       \RETURN $Current$
\end{algorithmic}
\end{algorithm}


In order to complete the description is important to specify the way to calculate $D_d$ and the way to update the 
elite individuals.
%
The remaining steps are maintained as in the classic \DE{} variant.
%
The value of $D_d$ should depend on the optimization stage.
%
Specifically, this value should be reduced as the stopping criterion is approached.
%
In our scheme, an initial $D_I$ value must be set.
%
Then, a linear reduction of $D_t$ is done.
%
Particularly, in this work, the stopping criterion is set by function evaluations (nfes).
%
The reduction is calculated in such way that by the $95\%$ of maximum number of evaluations the resulting $D_t$ value is $0$, and the rest is present a similar behavior of the classical DE.
%
Thus, if $max\_nfes$ is the maximum number of evaluations and $nfes$ the elapsed number of evaluations, $D_t$ can be calculated as $D_t=D_I - D_I *(nfes/(0.95*max\_nfes))$.
%
According to Segura et al. \cite{segura2016novel} updating $D_t$ is more appropriate through a linear reduction.
%


%
Specifically, the previously strategy is implemented in the replacement phase  where is used a popular niche-strategy known as \textit{Speciation} \cite{yang2017multimodal}.
%
Initially, based in a niche-radius ($D_t$) and a defined distance\footnote{For simplicity we use euclidean distance, however can be user other distance as the mahalanobis distance.} (equation \ref{eqn:distance}), in an iterative process the seeds (or survivors) are identified, these are the vectors with best fitness and whose minimal DCN is not lower than the one determined by the $D_t$ value.
%
It is important to remark that should be considered the normalized distance in such way that each dimension is equally important and the maximum distance is the unity, and as is suggested in previous works the initial niche-radius ($D_I$) is the fraction of the main space diagonal.

\begin{equation}\label{eqn:distance}
distance ( x_{seed}, x_j ) = \frac{\sqrt{ \sum_{d=1}^D \left ( \frac{x_{seed}^d - x_j^d}{max_d - min_d} \right )^2  }} {\sqrt{D}}
\end{equation}

%
Therefore, the vectors that have a lowest distance to any seed than $D_t$ are moved to the penalized set.
%
In this way are preserved the best fitness vectors and simultaneously the diversity is maintained in some level.
%
It is important to take into account that if the niche-radio is too high, just one seed or survivor will be selected.
%
In this scenario the rest of parent vectors are selected from the penalized vectors.
%
Thus, are selected the penalize vectors that have the maximum contribution to diversity considering the selected seeds vectors.
%
Although that in the literature exist several diversity measures, we consider the DCN.
%
According this, in an iterative process is selected as survivor the penalized vector that has the maximum DCN.


On the other hand, since that the diversity in the parent vectors should be kept, the selection operator indicated in the equation (\ref{eqn:selection}) is modified.
%
Thus, instead of made a comparison between the target or parent vectors and the trial or offspring vectors, is applied a comparison between the offspring vectors with the elite vectors.
%
Hence, the elite vectors record the best individuals obtained among the optimization process.
%


\begin{algorithm}[H]
\algsetup{linenosize=\tiny}
  \scriptsize
	\caption{General scheme of DE considering diversity} 
	\begin{algorithmic}[1]
	\STATE Randomly initialize the population of $NP$ individuals, where each one is uniformly distributed.
	\STATE Update $D_t = D_I - D_I *(nfes/(0.95*max\_nfes)) $ 
	\WHILE{ stopping criterion is nor satisfied}
	   \FOR{ $i=1$ to $NP$} 
		\STATE Mutation: Generate the donor vector according Eq. (\ref{eqn:mutation})
		\STATE Crossover: Recombine the mutate vector according Eq. (\ref{eqn:crossover})
		\STATE Selection: Update the parent vector according  Eq. (\ref{eqn:selection})
		\STATE Replacement: Select the parent vectors according to algorithm \ref{alg:Replacement}
	   \ENDFOR
	\ENDWHILE
    \label{alg:Fase_Remplazo_VSD-MOEAD}
\end{algorithmic}
\end{algorithm}


An advantage of our proposal is that it alleviates one critical weakness of the DE algorithms.
%
These are the control parameters both crossover probability ($CR$) and mutation factor ($F$).
%
Based in several studies showed by Montgomery et al. \cite{montgomery2010analysis}, $CR$ is perhaps the most important.
%
Extremes $CR$ values leads to vastly different search behaviors.
%
Low values of $CR$ result in a search that is not just aligned with a small number of search space axes, but which is gradual, slow and robust.
%
High values of $CR$ result in searches where fewer generated solutions may be improving, but the improvements can be large.
%
According this, we employ both high and low $CR$ values showed in the equation \ref{eqn:cr}.

\begin{equation} \label{eqn:cr}
CR = 
\begin{cases}
     Norm(0.2, 0.1),& \text{if} \quad rand[0,1] \leq 0.5  \\
     Norm(0.9, 0.1),              & \text{otherwise}
\end{cases}
\end{equation}


On the other hand, the mutation factor $F$ is computed as follows.
%
For each vector is sampled a $F$ value with a Cauchy distribution $Cauchy(0.5, 0.5*nfes/max\_nfes)$.
%
In this way the shape of the distribution increases with the function evaluations and therefore are generated more extreme values at the end of execution, this aims avoid stagnation in different stages of the algorithm.
%


Our proposal is based in several ideas of the previously mentioned works, specifically the following:
\begin{itemize}
\item Is considered a threshold to control explicitly the convergence of the solutions.
\item This threshold decreases over the algorithm's run.
\item The selection operator is relaxed. 
\end{itemize}

