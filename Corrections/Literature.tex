\subsection{Differential Evolution: Basic Concepts}

This section is devoted to summarize the classic \DE{} variant and to introduce some of the most important terms used in the \DE{} field.
%
The classic \DE{} scheme is called the \DE{}/rand/1/bin and it has been extensively used to generate more complex \DE{} variants~\cite{das2011differential}.
%
In fact, our proposal also extends the classic variant.
%
%However, in order to perform fair comparisons,
%our experimental validation takes into account state-of-the-art approaches that incorporate more complex 
%components and even algorithms not belonging to the \DE{} field.
%
\DE{} was originally proposed as a direct search method for single-objective continuous optimization.
%
The variables governing a given problem performance are given as a vector like $\vec{X} = [x_1, x_2, ..., x_D]$, where $D$ is the
dimension of the problem.
%
In continuous optimization, each $x_i$ is a real number and usually box-constraints are given, i.e. there is a lower bound ($a_{i}$) and
upper bound ($b_{i}$) for each variable.
%
The aim of the optimization process is to obtain the vector $\vec{X}^*$ which minimizes a given objective function, mathematically 
denoted by $f : \Omega \subseteq \Re^D \rightarrow \Re$.
%
In the box-constrained case $\Omega = {\prod}_{j=1}^{D} [a_{j}, b_{j}]$.

\DE{} is a population-based stochastic algorithm, so it iteratively evolves a multi-set of candidate solutions.
%
In \DE{} such candidate solutions are usually called vectors.
%
In the basic \DE{} variant for each member of the population --- they are called \textit{target vectors} --- a new \textit{mutant vector}
is created.
%
Then, the mutant vector is combined with the target vector to generate a \textit{trial vector}.
%
Finally, a selection phase is applied to choose the survivors.
%
In this way, several generations are evolved until a stopping criterion is reached.
%
The $i$-th vector of the population at the generation $G$ is denoted as $\vec{X}_{i,G} = [x_{1,i,G}, x_{2,i,G},..., X_{D,i, G}]$.
%
In the following more details are given for each component of \DE{}.


\subsubsection{Initialization}

\DE{} usually starts the optimization process with a randomly initiated population of $N$ vectors.
%
Since there is commonly no information about the performance of different regions, uniform random generators are usually applied.
%
Hence, the $j$-th component of the $i$-th vector is initialized as $x_{j,i,0} = a_{j} + rand_{i,j}[0,1] (b_{j} - a_{j})$,
where $rand_{i,j}[0,1]$ is an uniformly distributed random number lying between $0$ and $1$.

\subsubsection{Mutation}

For each target vector a mutant vector is created and several ways of performing
such a process have been proposed.
%
In the classic \DE{} variant the rand/1 strategy is applied.
%
In this case, the mutant vector $V_{i,G}$ is created as follows:

\begin{equation}\label{eqn:mutation}
\vec{V}_{i,G} = \vec{X}_{r_1, G} + F \times (\vec{X}_{r_2, G} - \vec{X}_{r_3, G}) \quad r_1 \neq r_2 \neq r_3
\end{equation}
%
The indices $r_1, r_2, r_3 \in [1,N]$ are mutually different integers randomly chosen from the range $[1, N]$.
%
In addition, they are all different from the index $i$.
%
It is important to take into account that the difference between vectors is scaled with the number F, which is usually defined in the interval $[0.4, 1]$.
%
The scaled difference is added to a third vector, meaning that
when diversity decreases and consequently differences are low, mutant vectors are similar to target vectors.
%
As a result, maintaining some degree of diversity is specially important in \DE{}.

\subsubsection{Crossover}

In order to combine information of different candidate solutions and with the aim of increasing diversity, the crossover
operator is applied.
%
Specifically, each target vector $\vec{X}_{i,G}$ is mixed with its corresponding mutant vector $V_{i,G}$ to 
generate the trial vector $\vec{U_{i,G}} = [u_{1,i,G},u_{2,i,G}, ..., u_{D,i,G} ]$.
%
The most typical crossover is the \textit{binomial} one, which operates as follows:
%
\begin{equation} \label{eqn:crossover}
\vec{U}_{j,i,G}= 
\begin{cases}
    \vec{V}_{j,i,G},& \text{if} (rand_{i,j}[0,1] \leq CR \quad or \quad j = j_{rand}  )\\
    \vec{X}_{j,i,G},              & \text{otherwise}
\end{cases}
\end{equation}
where $rand_{i,j}[0,1]$ is a uniformly distributed random number,
$j_{rand}$ is a randomly chosen index which ensures that $\vec{U}_{i,G}$ inherits at least one component from $\vec{V}_{i,G}$ and
$CR \in [0,1]$ is the crossover rate.


\subsubsection{Selection}
Finally, a greedy selection is performed to determine the survivors of the next generation.
%
Each trial vector is compared with its corresponding target vector and the best one survives:

\begin{equation} \label{eqn:selection}
\vec{X}_{j,i,G+1}= 
\begin{cases}
    \vec{U}_{i,G},& \text{if} \quad f(\vec{U}_{i,G}) \leq f(\vec{X}_{i,G})  \\
    \vec{X}_{i,G},              & \text{otherwise}
\end{cases}
\end{equation}

Hence, each population member either gets better or remains with the same objective value in each generation.
%
Since members never deteriorate, it is considered to be a selection with high pressure.
%
Note that in case of a tie, the trial vector survives.

%
%The general convention is DE/\textit{x}/\textit{y}/\textit{x}, where DE indicates ``Differential Evolution'', \textit{x} denotes the base vector to be perturbed, \textit{y} is the number of difference vectors considered for perturbation and \textit{z} is the type of crossover to use.



\subsection{Diversity Preservation in Evolutionary Algorithms}

Given that premature convergence is a common drawback in  \EAS{}, several variants to deal with this issue have been designed \cite{eshelman1993real}.
%
Some of them start with a set of diverse candidate solutions, and as the generations evolve, such a diversity is reduced \cite{Crepinsek:13}.
%
Depending on the component of the \EA{} that is modified, these methods are usually classified in one the following groups~\cite{Crepinsek:13}: \textit{selection-based}, \textit{population-based}, \textit{crossover/mutation-based}, \textit{fitness-based}, and \textit{replacement-based}.
%
Recently, the replacement-based strategies have attained quite good performance, therefore this section is devoted to this kind
of methods.
%
Particularly, two different strategies that are used to validate our proposal are discussed.
%
One of the first techniques categorized as replacement-based are the \textit{crowding} methods.
%
A quite popular popular realization is the \textit{Restricted Tournament Selection} \cite{harik1995finding} (\RTS{}) strategy.
%
In \RTS{} after a new individual ($C$) is created, then $CF$ individuals from the current population are randomly selected.
%
Then, $C$ and its most similar individual --from those in the selected set-- compete for a place in the population using a traditional binary tournament, i.e. the best one survives.
%

Other strategies are based on considering the diversity to calculate a fitness value for the replacement stage.
%
Specifically, in the \textit{Hybrid Genetic Search with Adaptive Diversity Control} (\HGSADC{}) \cite{vidal2013hybrid}, the individuals --union of parents and offspring-- are sorted by their contribution to diversity and by their original cost.
%
In order to calculate the contribution to diversity of an individual, its mean distance to the closest 
$N_{Close}$ individuals is calculated.
%
For an individual $I$, the ranking in terms of diversity is denoted as $RD(I)$, whereas the ranking for the original cost is denoted as $RC(I)$.
%
Then, the rankings are combined to generate the biased fitness value $BF(I)$ using the Eq. \ref{eqn:biased}.
%
In each step of the replacement phase, the individual with the lowest biased fitness is erased and the ranks are re-calculated.
%
This process is performed until the desired population size is attained.
%
It is important to remark that this scheme requires the setting of the parameters: $N_{Close}$ and $N_{Elite}$,
whereas $N_{population}$ refers to the number of individuals that has not been erased yet by the replacement scheme.

\begin{equation}\label{eqn:biased}
 BF(I) = RC(I) + \left(1- \frac{N_{Elite}}{N_{population}} \right) RD(I)
\end{equation}
\subsection{Diversity in Differential Evolution}

\DE{} is highly susceptible to the loss of diversity due to the greedy strategy applied in the selection phase.
%
Thus, several analyses to better deal with this issue have been carried out.
%
Since the general implications of each \DE{} parameter on the diversity are known, one of
the alternatives is to theoretically estimate proper values for the \DE{} parameters~\cite{zaharie2003control}.
%
Differently, some analyses regarding the effects of the magnitude of the difference vectors used in the mutation
%Differently, some analyses regarding the effects of the Euclidean norm of the difference vectors used in the mutation
have also been performed~\cite{montgomery2009differential}.
%
Such analyses and additional empirical studies regarding the crossover allowed to conclude that some kind of movements 
should be disallowed to delay the convergence~\cite{montgomery2012simple}.
%
In this last study the kind of accepted movements varies along the run.
%
Specifically, it discards movements with a norm below a threshold and this threshold decreases taking into account the elapsed generations.
%
Other ways of altering the kind of accepted movements have been proposed~\cite{bolufe2013differential}.
%
Note that these kinds of methods have similarities with our proposal in the sense that decisions are biased by the number of elapsed generations.
%
However, our method operates on the replacement strategy and not on the mutation phase.
%
Moreover, these methods do not consider explicitly the differences appearing on the whole population.
%
Instead, the restrictions apply to the differences appearing in the reproduction phase.

A different alternative operates by altering the selection operator~\cite{sa2008exploration}.
%
Particularly, the selection pressure is relaxed through a probabilistic selection to maintain the population diversity and consequently 
to allow escaping from basin of attraction of local optima.
%
Since it considers the fitness to establish the acceptance probabilities, it is very sensitive to scale transformations.
%
In this case, decisions are not biased by the elapsed generations.

Finally, in the \textit{Auto-Enhanced Population Diversity} (\textsc{aepd}), the diversity is explicitly measured and it triggers a mechanism
to diversify the population when a too low diversity is detected~\cite{yang2015differential}.
%
Strategies with similar principles but with different disturbance schemes have also been devised~\cite{zhao2016differential}.

Note that \DE{} variants with best performance in competitions do not apply these modifications
and that most of these extensions have not been implemented in the most widely used optimization frameworks.
%
As a result, these extensions are not so widely used in the community in spite of their important benefits
for some cases.

