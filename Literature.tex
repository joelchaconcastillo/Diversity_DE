\subsection{Differential Evolution: Basic Concepts}
In the literature are present several variants of DE ref1 ref8.
%
For simplicity, in this work is used the classic DE scheme references... "survey-state-art"
%
Origininally DE was proposed as direct search method for single-objective continuous optimization problems ref44(improving).
%
Usually, the parameters governing the system performance are presented in a vector like $\vec{X} = [x_1, x_2, ..., x_D ]^T$, which is identified as an individual.
%
Particularly, for real parameter optimization each parameter $x_i$ is a real number.
%

In single-objective optimization, the aim is to obtain the vector $\vec{X}^*$ wich minimizes (or maximize) a defined objective function, mathecally denoted by $f(\vec{X})(f : \Omega \subseteq \Re^D \rightarrow \Re)$, i.e., $f(\vec{X}^*) < f(\vec{X})$ for all $\vec{X} \in \Omega$, where $\Omega$ is a non-empty large finite set identified as the domain of the search.
%

The basic scheme of DE consists that given the target parameter vectors (each vector of the population), a new mutant (or donant) vector is created using a vector generation strategy.
%
After that, the mutant vector is combined with the target vector to generate the trial vector.
%
In the same vein, each one of the trial vectors is compared with the correspond target vector, and the vector with the best fitness is select to survive as trial vector of the next generation.
%
In case of tie, the new generated trial vector survives.


\subsubsection{Initialization}


The DE algorithms as is usual begins with a randomly initiated population of $NP$ parameter vectors.
%
Subsequent generations in DE are denoted by $G= 0,1, ..., G_{max}$.
%
The $i$th vector of the population at the current generation is denoted as:
\begin{equation} 
\vec{X}_{i,G} = [x_{1,i,G}, x_{2,i,G},..., X_{D,i, G}].
\end{equation}
%

The initial population should cover a bounded range and is reached by uniformly randomizing individuals within the search space constrained by the prescribed minimum and maximum bounds.
%
Hence, each $j$th component of the $i$th vector is initialized as follow:
\begin{equation}
X_{j,i,0} = x_{j,min} + rand_{i,j}[0,1] (x_{j,max} - x_{j_min})
\end{equation}
where $rand_{i,j}[0,1]$ is a uniformly distribuited random number lying between $0$ and $1$.

\subsubsection{Mutation}
The mutation can be seen as a change or perturbation with a random element.
%
Particularly, in DE a parent vector called \textit{target} vector is combined through a defined strategy to form the \textit{donor} vector.
%
In one simple form, a mutant vector $V_{i,G}$ is created from the $i$th target vector and is stablished as follows:
\begin{equation}\label{eqn:mutation}
\vec{V}_{i,G} = \vec{X}_{r1, G} + F(\vec{X}_{r2, G} - \vec{X}_{r3, G}) \quad r1 \neq r2 \neq r3
\end{equation}
%
The indices $r1, r2, r3 \in [1,NP]$ are mutually exclusive integers randomly chosen from the range $[1, NP]$.
%
It is important take into account that the difference of any two vectors is scaled by a scalar number F and usually is defined in the interval $[0.4, 1]$, also the scale difference is added to the third one.
%

\subsubsection{Crossover}

In order to increase the diversity of the perturbed parameter vectors, a crossover operation is aplied to the generated donor vector.
%
Accordingly this, the target vector is mixed with the mutated vector to form the trial vector $\vec{U_{i,G}} = [u_{1,i,G},u_{2,i,G}, ..., u_{D,i,G} ]$.
%
In the DE-context are present two kinds of crossover methods --\textit{exponential} and \textit{binomial}(or uniform), however in this paper only is considered the binomial crossover.
%
In the binomial crossover strategy, the trial vector $\vec{U}_{i,G}$ is generated as follows:
%
\begin{equation} \label{eqn:crossover}
\vec{U}_{j,i,G}= 
\begin{cases}
    \vec{V}_{j,i,G},& \text{if} (rand_{i,j}[0,1] \leq CR \quad or \quad j = j_{rand}  )\\
    \vec{X}_{j,i,G},              & \text{otherwise}
\end{cases}
\end{equation}
where $rand_{i,j}[0,1]$ is a uniformly distribuited random number, which is generated for each $j$th component of the $i$th vector parameter.
%
$j_{rand}$ is a randomly chosen index, which ensures that $\vec{U}_{i,G}$ has at least one component from $\vec{V}_{i,G}$.
%
$CR$ is the crossover constant $\in [0,1]$, which has to be determined by the user.


\subsubsection{Selection}
Once generated the trial vectors, is performed a greedy selection scheme.
%
This selection determine wheter the target or the trial vector survives to the next generation, and is described as follows:

\begin{equation} \label{eqn:selection}
\vec{X}_{j,i,G+1}= 
\begin{cases}
    \vec{U}_{i,G},& \text{if} \quad f(\vec{U}_{i,G}) \leq f(\vec{X}_{i,G})  \\
    \vec{X}_{i,G},              & \text{otherwise}
\end{cases}
\end{equation}

where $f(\vec{X})$ is the objective function to be minimized.
%
Hence, the population eigher gets better or remains the same fitness status, but never deteriorates.

The mutation scheme decribed with the crossover proposed is refered as DE/rand/1/bin.
%
The general convention is DE/\textit{x}/\textit{y}/\textit{x}, where DE indicates ``differential evolution'', \textit{x} denotes the base vector to be perturbed, \textit{y} is the number of difference vectors considered for perturbation and \textit{z} is the type of crossover to use.

------Diversity Revision
*Explain the influence of the paramters.
*Show the implication of these operators with the population diversity.
*Talk about hybrid and adaptive strategies.



\subsection{Differential Evolution and Diversity techniques}

DE is highly susceptible to the diversity drawbacks generally seen in EAs.
%
This fact is since the selection pressure is very aggresive, well known as a greedy strategy.
%
However througth the last decade has developed several analyses and strategies to deal with these drawbacks.
%
One of them is proposed in 2003 by Zaharie et al.  \cite{zaharie2003control} estimated the theorical variance and proposes a parameter adaptation througth two critical equations based on the idea of controlling the population diversity.
%
In 2009 James Montgomery \cite{montgomery2009differential} analyses the effect of the difference vectors showing that small differences vectors applied to solutions in one cluster can produce improvementes, thus movements produced by large difference vectors are wasted.
%
After that in 2010 Montgomery shows a study where are analyzed the DE parameters, principally is empirically demostrated the effect of the crossover probability.
%
In 2012 Montgomery et al. \cite{montgomery2012simple} proposed a strategy that prevents the movements vectors that could provoke premature convergence, specifically it prevents the movements that are below a threshold and it decreases over the algorithm's run.
%
Also in 2013 derived of this strategy is proposed an adaptive thresheld convergence mechanism by Antonio et al. \cite{bolufe2013differential}.
%
One of them, proposed in \cite{sa2008exploration} by Angela et al. suggest a modification of the selection used in the classical DE, where the seleciton pressure is relaxed, thus is implemented a probabilistic selection to maintain the population diversity and consequently to allow scape from basin of attraction of local optima, however to compute the probabilistic selection is considered the fitness therefore it depends in the cost funcition.
%

Ming Yang et al. (2013) \cite{yang2015differential} proposed a mechanism named \textit{Auto-Enhanced Population Diversity} (AEPD) where are identified the moments when a population becomes converging or stagnating by measuirng the distribution of the population in each dimension and diversing at the dimensional level.
%
Similar strategies has been proposed as the one by Zhao Li et al. in 2016 \cite{zhao2016differential} where are variated the assembling positions of the premature individuals by mutation operation.

Despite the fact that are developed techinques where is explicitly induced a balance between explotation and exploration through a threshold of diversity (Montgomery), and mechanisms that modify the selection of differential evolution, there is not present a strategies with both principles.
